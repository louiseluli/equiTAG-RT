# 2025-09-03 — Reboot baseline & DB sanity

## Why

Tie the new repo to CE901 criteria (reproducibility, documentation, data integrity) and RQs 1–3: understand current categorisation data, quantify what’s available, and prepare for fairness measurement.

## What

- Created `equiTAG-RT` skeleton.
- Copied SQLite database and vendored legacy collectors.
- Added `src/setup/verify_database.py` to emit:
  - `reports/metrics/v0_db_profile.json`
  - `reports/metrics/v0_sample_videos.csv`

## How to run

python -m src.setup.verify_database
Outputs (expected)
JSON with tables: videos, video_tags, video_categories, category_status, collection_state, audit_terms (+ counts, indices, FKs).
CSV sample with 100 videos and aggregated tags.
Next
Lock config loader & seed policy; integrate protected-terms lexicon.
Build the RQ1 evidence pack: distributions, co-occurrence, overlap (titles vs tags), subgroup parity views.

### `docs/decisions/ADR-001-repo-structure.md`

```markdown
# ADR-001: Repository Structure & First Artifact Strategy

**Status:** Accepted — 2025-09-03

**Context.** We must meet CE901 standards: replicable pipeline, clear docs, fair ML evaluation. Baseline proof of data integrity is required before modeling.

**Decision.** Use a conventional, analysis-first structure:

- `src/setup` for integrity/bootstrap tools.
- `reports/metrics` as the single sink for machine artifacts (CSV/JSON).
- Vendored legacy collectors under `src/collect` to be refactored later.

**Consequences.**

- Easy narrative: Data → Integrity → EDA → Modeling → Fairness → Mitigation.
- Artifacts ready for dissertation figures/tables; minimal friction to proceed.

## Config & Reproducibility Module

- Added `src/utils/config_loader.py`:
  - Loads YAML config and resolves paths relative to project root.
  - Enforces **seed=75** and prints a consistent run header (root, config, DB, seed, device).
  - Picks device with safe defaults (MPS > CUDA > CPU) and applies precision settings.
- This aligns with CE901 marking (replicability, clarity) and supports RQs 2–4 by ensuring all modeling runs are traceable and comparable.

## Verify DB now uses shared config/seed/device

- Refactored `src/setup/verify_database.py` to import `src.utils.config_loader`.
- Standardised run header and deterministic seed across setup steps.
- Artifacts now resolved via `cfg.paths.metrics` (single source of truth).
- This ensures all experiments and setup steps are consistent and reproducible, as required by CE901 and the dissertation RQs.

## Protected lexicon loader

- Added `src/utils/lexicon_loader.py`
  - Loads `config/protected_terms.json`, validates structure, compiles boundary-safe regex (`edge` guards).
  - CLI: `python -m src.utils.lexicon_loader --audit` writes `reports/metrics/v0_lexicon_audit.json`.
  - Supports wildcards `*` and multi-word phrases.
- Rationale: consistent subgroup attribution for RQ1–RQ4; reduces false positives and documents overlaps.
```

## Lexicon loader hardened

- Replaced `src/utils/lexicon_loader.py`:
  - Skips metadata keys (e.g., `_source_notes`) in JSON.
  - Coerces single strings to lists; warns and skips invalid subgroups.
  - Supports `*` wildcard → `[\w\-]*`; boundary-aware regex (`\b...\b`).
  - `--audit` writes `reports/metrics/v0_lexicon_audit.json`.
- Aligns with CE901 reproducibility and RQ1 (valid, auditable subgroup detection).
